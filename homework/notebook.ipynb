{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"../files/input/auto_mpg.csv\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Tamaño del dataset\n",
    "#\n",
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Búsqueda de valores nulos\n",
    "#\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Se eliminan los registros nulos\n",
    "#\n",
    "dataset = dataset.dropna()\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Columna origin\n",
    "# Nota: 1) USA\n",
    "#       2) EUROPE\n",
    "#       3) japan\n",
    "dataset.Origin.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Convierte la columna a categorías\n",
    "# Nota. Realmente no se debería hacer así para aplicaciones\n",
    "# en productivo\n",
    "#\n",
    "dataset[\"Origin\"] = dataset[\"Origin\"].map(\n",
    "    {1: \"USA\", 2: \"Europe\", 3: \"Japan\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Genera variables dummy para indicar la procedencia\n",
    "#\n",
    "dataset = pd.get_dummies(dataset, columns=[\"Origin\"], prefix=\"\", prefix_sep=\"\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Note que aca no se usa train_test_split\n",
    "#\n",
    "train_dataset = dataset.sample(frac=0.8, random_state=0)\n",
    "test_dataset = dataset.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Las millas por galon (MPPG) son función d elas demás variables.\n",
    "#\n",
    "import seaborn as sns\n",
    "\n",
    "sns.pairplot(\n",
    "    train_dataset[[\"MPG\", \"Cylinders\", \"Displacement\", \"Weight\"]], diag_kind=\"kde\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Cálculo de algunas estadísticas generales\n",
    "#\n",
    "train_dataset.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_features = train_dataset.copy()\n",
    "test_features = test_dataset.copy()\n",
    "\n",
    "train_labels = train_features.pop(\"MPG\")\n",
    "test_labels = test_features.pop(\"MPG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset.describe().transpose()[[\"mean\", \"std\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Efecto del StandardScaler\n",
    "#\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "pd.DataFrame(\n",
    "    data=scaler.fit_transform(train_dataset),\n",
    "    columns=train_dataset.columns,).describe().transpose()[[\"mean\", \"std\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# REGRESION LINEAL CON UN VARIABLE\n",
    "# ------------------------------------------------------\n",
    "#\n",
    "# Preparación de la data\n",
    "#\n",
    "horsepower_scaler = StandardScaler()\n",
    "\n",
    "train_horsepower = train_features[[\"Horsepower\"]]\n",
    "test_horsepower = test_features[[\"Horsepower\"]]\n",
    "\n",
    "horsepower_scaler.fit(train_horsepower)\n",
    "\n",
    "standarized_train_horsepower = horsepower_scaler.transform(train_horsepower)\n",
    "standarized_test_horsepower = horsepower_scaler.transform(test_horsepower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Modelo de regresión lineal\n",
    "#\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "horsepower_model = LinearRegression()\n",
    "horsepower_model.fit(standarized_train_horsepower, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Intercept\n",
    "#\n",
    "horsepower_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Coeficientes\n",
    "#\n",
    "horsepower_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Predicción. Prearación de las variables independientes\n",
    "#\n",
    "import numpy as np\n",
    "\n",
    "x = pd.DataFrame({\"Horsepower\": np.linspace(0, 250, 251)})\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Predicción\n",
    "#\n",
    "scaled_x = horsepower_scaler.transform(x)\n",
    "y = horsepower_model.predict(scaled_x)\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_horsepower(x, y):\n",
    "    plt.scatter(train_features[\"Horsepower\"], train_labels, label=\"Data\")\n",
    "    plt.plot(x, y, color=\"k\", label=\"Predictions\")\n",
    "    plt.xlabel(\"Horsepower\")\n",
    "    plt.ylabel(\"MPG\")\n",
    "    plt.legend()\n",
    "\n",
    "    \n",
    "plot_horsepower(x, y)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluación\n",
    "#\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "test_results = {}\n",
    "\n",
    "y_pred = horsepower_model.predict(standarized_test_horsepower)\n",
    "\n",
    "test_results[\"horsepower_model\"] = mean_squared_error(\n",
    "    y_true = test_labels,\n",
    "    y_pred=y_pred,\n",
    ")\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Preparación de la data\n",
    "#\n",
    "features_scaler = StandardScaler()\n",
    "\n",
    "features_scaler.fit(train_features)\n",
    "\n",
    "standarized_train_features = features_scaler.transform(train_features)\n",
    "standarized_test_features = features_scaler.transform(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()\n",
    "linear_model.fit(standarized_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Interceptos\n",
    "#\n",
    "linear_model.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Coeficientes\n",
    "#\n",
    "linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred):\n",
    "\n",
    "    ax = plt.axes(aspect=\"equal\")\n",
    "    plt.scatter(y_true, y_pred)\n",
    "    plt.xlabel(\"True Values [MPG]\")\n",
    "    plt.ylabel(\"Predictions [MPG]\")\n",
    "    lims = [0, 50]\n",
    "    plt.xlim(lims)\n",
    "    plt.ylim(lims)\n",
    "    _ = plt.plot(lims, lims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "  \n",
    "test_predictions = linear_model.predict(standarized_test_features)\n",
    "\n",
    "plot_predictions(\n",
    "    y_true=test_labels,\n",
    "    y_pred=test_predictions,\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_results[\"linear_model\"] = mean_squared_error(\n",
    "    y_true=test_labels,\n",
    "    y_pred=test_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# RED NEURONAL CON UNA SOLA ENTRADA\n",
    "# -------------------------------------\n",
    "#\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "mlp_horsepower = MLPRegressor(\n",
    "    max_iter=10000,\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    learning_rate_init=0.001,\n",
    "    validation_fraction=0.2,\n",
    "    early_stopping=True,\n",
    "    random_state=0,\n",
    ")\n",
    "mlp_horsepower.fit(standarized_train_horsepower, train_labels)\n",
    "\n",
    "y = mlp_horsepower.predict(scaled_x)\n",
    "plot_horsepower(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = mlp_horsepower.predict(standarized_test_horsepower)\n",
    "\n",
    "test_results[\"mlp_horsepower\"] = mean_squared_error(\n",
    "    y_true=test_labels,\n",
    "    y_pred=y_pred,\n",
    ")\n",
    "\n",
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# RED NEURONAL CON TODAS LAS VARIABLES\n",
    "# --------------------------------------------\n",
    "#\n",
    "mlp = MLPRegressor(\n",
    "    max_iter=10000,\n",
    "    hidden_layer_sizes=(64, 64),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    learning_rate_init=0.001,\n",
    "    validation_fraction=0.2,\n",
    "    early_stopping=True,\n",
    "    random_state=0,\n",
    ")\n",
    "mlp.fit(standarized_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_predictions = mlp.predict(standarized_test_features)\n",
    "\n",
    "plot_predictions(\n",
    "    y_true=test_labels,\n",
    "    y_pred=test_predictions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "test_results[\"mlp\"] = mean_squared_error(\n",
    "    y_true=test_labels,\n",
    "    y_pred=test_predictions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(test_results, index=[\"Mean squared error [MPG]\"]).T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#\n",
    "# ALMACENAMIENTO DEL MODELO\n",
    "#\n",
    "import pickle\n",
    "\n",
    "with open(\"mlp.pickle\", \"wb\") as file:\n",
    "    pickle.dump(mlp, file)\n",
    "\n",
    "with open(\"features_scaler.pickle\", \"wb\") as file:\n",
    "    pickle.dump(features_scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# USO DEL MODELO\n",
    "#\n",
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(\"../files/input/auto_mpg.csv\")\n",
    "dataset = dataset.dropna()\n",
    "dataset[\"Origin\"] = dataset[\"Origin\"].map(\n",
    "    {1: \"USA\", 2: \"Europe\", 3: \"Japan\"},\n",
    ")\n",
    "dataset = pd.get_dummies(dataset, columns=[\"Origin\"], prefix=\"\", prefix_sep=\"\")\n",
    "y_true = dataset.pop(\"MPG\")\n",
    "\n",
    "\n",
    "with open(\"mlp.pickle\", \"rb\") as file:\n",
    "    new_mlp = pickle.load(file)\n",
    "\n",
    "with open(\"features_scaler.pickle\", \"rb\") as file:\n",
    "    new_features_scaler = pickle.load(file)\n",
    "\n",
    "standarized_dataset = new_features_scaler.transform(dataset)\n",
    "y_pred = mlp.predict(standarized_dataset)\n",
    "\n",
    "mean_squared_error(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
